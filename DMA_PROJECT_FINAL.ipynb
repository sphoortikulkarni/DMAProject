{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic: 'What Do You Know'\n",
    "# problem statement:Improve the state of art in the student evaluation by predicting whether a student will answer the next test question correctly .\n",
    "# Team Members: \n",
    "#             Shreyas Joshi              301       \n",
    "#           Sphoorti Kulkarni          310\n",
    "#            Sumaiya Garag              317\n",
    "#            Sunidhi P Naik             318\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# First all the libraries provided by ananconda which will be useful for the work are imported . \n",
    "# As the work progresses further , the needed libraries are imported accordingly ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%pylab inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#After importing the libraries , the first thing to do is to is to read the needed file(s) for the prediction ,\n",
    "#into variable(s)\n",
    "#For our predcition , we need two files train data (valid_training.csv) and test data (valid_test.csv) . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load train data\n",
    "train_users = pd.read_csv('valid_training.csv',nrows=1000000, dtype={'correct':np.uint8,'user_id':np.uint16,'answer_id':np.uint16,\n",
    "                    'track_name':np.uint32,'outcome':np.uint8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>outcome</th>\n",
       "      <th>user_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question_type</th>\n",
       "      <th>group_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>subtrack_name</th>\n",
       "      <th>tag_string</th>\n",
       "      <th>round_started_at</th>\n",
       "      <th>answered_at</th>\n",
       "      <th>deactivated_at</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>game_type</th>\n",
       "      <th>num_players</th>\n",
       "      <th>date_of_test</th>\n",
       "      <th>question_set_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20282</td>\n",
       "      <td>5560</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>222 233 240 246</td>\n",
       "      <td>2010-08-18 20:17:13</td>\n",
       "      <td>2010-08-18 20:18:18</td>\n",
       "      <td>2010-08-18 20:18:18</td>\n",
       "      <td>6540</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20282</td>\n",
       "      <td>4681</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>24 49</td>\n",
       "      <td>2010-08-18 20:19:12</td>\n",
       "      <td>2010-08-18 20:20:34</td>\n",
       "      <td>2010-08-18 20:20:34</td>\n",
       "      <td>4742</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20282</td>\n",
       "      <td>1529</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>31 49</td>\n",
       "      <td>2010-08-18 20:20:42</td>\n",
       "      <td>2010-08-18 20:21:56</td>\n",
       "      <td>2010-08-18 20:21:56</td>\n",
       "      <td>4309</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20282</td>\n",
       "      <td>2908</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>31 49</td>\n",
       "      <td>2010-08-18 20:22:03</td>\n",
       "      <td>2010-08-18 20:23:05</td>\n",
       "      <td>2010-08-18 20:23:05</td>\n",
       "      <td>4408</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20282</td>\n",
       "      <td>1773</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>183 194 207</td>\n",
       "      <td>2010-08-18 20:23:11</td>\n",
       "      <td>2010-08-18 20:26:08</td>\n",
       "      <td>2010-08-18 20:26:08</td>\n",
       "      <td>10822</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   correct  outcome  user_id  question_id  question_type  group_name  \\\n",
       "0        0        2    20282         5560              0           1   \n",
       "1        1        1    20282         4681              0           1   \n",
       "2        1        1    20282         1529              0           1   \n",
       "3        1        1    20282         2908              0           1   \n",
       "4        1        1    20282         1773              0           1   \n",
       "\n",
       "   track_name  subtrack_name       tag_string     round_started_at  \\\n",
       "0           5             14  222 233 240 246  2010-08-18 20:17:13   \n",
       "1           5              0            24 49  2010-08-18 20:19:12   \n",
       "2           5              0            31 49  2010-08-18 20:20:42   \n",
       "3           5              0            31 49  2010-08-18 20:22:03   \n",
       "4           5             11      183 194 207  2010-08-18 20:23:11   \n",
       "\n",
       "           answered_at       deactivated_at  answer_id  game_type  \\\n",
       "0  2010-08-18 20:18:18  2010-08-18 20:18:18       6540          7   \n",
       "1  2010-08-18 20:20:34  2010-08-18 20:20:34       4742          7   \n",
       "2  2010-08-18 20:21:56  2010-08-18 20:21:56       4309          7   \n",
       "3  2010-08-18 20:23:05  2010-08-18 20:23:05       4408          7   \n",
       "4  2010-08-18 20:26:08  2010-08-18 20:26:08      10822          7   \n",
       "\n",
       "   num_players date_of_test  question_set_id  \n",
       "0            1          NaN             1567  \n",
       "1            1          NaN             1227  \n",
       "2            1          NaN             1148  \n",
       "3            1          NaN             1168  \n",
       "4            1          NaN             2318  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##train_users['outcome'] = train_users[train_users['outcome'] < 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now that data is loaded , checking the amount of null values in each attribute is the next thing . \n",
    "#This is a part of data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "answered_at       11.1711\n",
       "deactivated_at     0.0015\n",
       "date_of_test      80.1637\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## How much data we are missing?                \n",
    "## Compute NaN percentage of each feature.\n",
    "users_nan = (train_users.isnull().sum() / train_users.shape[0]) * 100\n",
    "users_nan[users_nan > 0]                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we have the cloumns in which null values are present and wat is the percentage of null values in them .\n",
    "# By general concepts , the attributes with null percentage of above 60% can be dropped .\n",
    "# It can be dropped because if the null percetage is big , deleteing that attribute will not make much difference\n",
    "# in the dataset . \n",
    "# Hence we are dropping date_of_test attribute ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>outcome</th>\n",
       "      <th>user_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question_type</th>\n",
       "      <th>group_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>subtrack_name</th>\n",
       "      <th>tag_string</th>\n",
       "      <th>round_started_at</th>\n",
       "      <th>answered_at</th>\n",
       "      <th>deactivated_at</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>game_type</th>\n",
       "      <th>num_players</th>\n",
       "      <th>question_set_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20282</td>\n",
       "      <td>5560</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>222 233 240 246</td>\n",
       "      <td>2010-08-18 20:17:13</td>\n",
       "      <td>2010-08-18 20:18:18</td>\n",
       "      <td>2010-08-18 20:18:18</td>\n",
       "      <td>6540</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20282</td>\n",
       "      <td>4681</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>24 49</td>\n",
       "      <td>2010-08-18 20:19:12</td>\n",
       "      <td>2010-08-18 20:20:34</td>\n",
       "      <td>2010-08-18 20:20:34</td>\n",
       "      <td>4742</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20282</td>\n",
       "      <td>1529</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>31 49</td>\n",
       "      <td>2010-08-18 20:20:42</td>\n",
       "      <td>2010-08-18 20:21:56</td>\n",
       "      <td>2010-08-18 20:21:56</td>\n",
       "      <td>4309</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20282</td>\n",
       "      <td>2908</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>31 49</td>\n",
       "      <td>2010-08-18 20:22:03</td>\n",
       "      <td>2010-08-18 20:23:05</td>\n",
       "      <td>2010-08-18 20:23:05</td>\n",
       "      <td>4408</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20282</td>\n",
       "      <td>1773</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>183 194 207</td>\n",
       "      <td>2010-08-18 20:23:11</td>\n",
       "      <td>2010-08-18 20:26:08</td>\n",
       "      <td>2010-08-18 20:26:08</td>\n",
       "      <td>10822</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   correct  outcome  user_id  question_id  question_type  group_name  \\\n",
       "0        0        2    20282         5560              0           1   \n",
       "1        1        1    20282         4681              0           1   \n",
       "2        1        1    20282         1529              0           1   \n",
       "3        1        1    20282         2908              0           1   \n",
       "4        1        1    20282         1773              0           1   \n",
       "\n",
       "   track_name  subtrack_name       tag_string     round_started_at  \\\n",
       "0           5             14  222 233 240 246  2010-08-18 20:17:13   \n",
       "1           5              0            24 49  2010-08-18 20:19:12   \n",
       "2           5              0            31 49  2010-08-18 20:20:42   \n",
       "3           5              0            31 49  2010-08-18 20:22:03   \n",
       "4           5             11      183 194 207  2010-08-18 20:23:11   \n",
       "\n",
       "           answered_at       deactivated_at  answer_id  game_type  \\\n",
       "0  2010-08-18 20:18:18  2010-08-18 20:18:18       6540          7   \n",
       "1  2010-08-18 20:20:34  2010-08-18 20:20:34       4742          7   \n",
       "2  2010-08-18 20:21:56  2010-08-18 20:21:56       4309          7   \n",
       "3  2010-08-18 20:23:05  2010-08-18 20:23:05       4408          7   \n",
       "4  2010-08-18 20:26:08  2010-08-18 20:26:08      10822          7   \n",
       "\n",
       "   num_players  question_set_id  \n",
       "0            1             1567  \n",
       "1            1             1227  \n",
       "2            1             1148  \n",
       "3            1             1168  \n",
       "4            1             2318  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop date_of_test \n",
    "train_users.drop('date_of_test',axis=1, inplace=True)\n",
    "\n",
    "train_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fill during post processing\n",
    "#train_users['answered_at'].fillna('0000-00-00', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_users['deactivated_at'].fillna('0000-00-00', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our data has the fields round_started_at , answered_at , deactivated_at . \n",
    "# All these three attributes have date and time .\n",
    "# Since we have droppeddat_of_test , we are going to split the each of the three attributes into two , where each\n",
    "# one eparated part containd the date and the other , time .\n",
    "# all the date columns generated are same . Hence there is redundent data .\n",
    "# So we will drop two of the date columns and rename the others ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split datetime to separate date and time attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding new fields...\n",
      "Adding new fields...completed\n"
     ]
    }
   ],
   "source": [
    "train_users['round_started_at'] = pd.to_datetime(train_users['round_started_at'],  errors='coerce')\n",
    "print(\"Adding new fields...\")\n",
    "train_users['round_started_at_date'] = train_users['round_started_at'].dt.date\n",
    "train_users['round_started_at_time'] = train_users['round_started_at'].dt.time\n",
    "print(\"Adding new fields...completed\")\n",
    "\n",
    "train_users.drop('round_started_at',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding new fields...\n",
      "Adding new fields...completed\n"
     ]
    }
   ],
   "source": [
    "train_users['answered_at'] = pd.to_datetime(train_users['answered_at'],  errors='coerce')\n",
    "print(\"Adding new fields...\")\n",
    "train_users['answered_at_date'] = train_users['answered_at'].dt.date\n",
    "train_users['answered_at_time'] = train_users['answered_at'].dt.time\n",
    "print(\"Adding new fields...completed\")\n",
    "\n",
    "train_users.drop('answered_at',axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding new fields...\n",
      "Adding new fields...completed\n"
     ]
    }
   ],
   "source": [
    "train_users['deactivated_at'] = pd.to_datetime(train_users['deactivated_at'],  errors='coerce')\n",
    "print(\"Adding new fields...\")\n",
    "train_users['deactivated_at_date'] = train_users['deactivated_at'].dt.date\n",
    "train_users['deactivated_at_time'] = train_users['deactivated_at'].dt.time\n",
    "print(\"Adding new fields...completed\")\n",
    "\n",
    "train_users.drop('deactivated_at',axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "correct                   uint8\n",
       "outcome                   uint8\n",
       "user_id                  uint16\n",
       "question_id               int64\n",
       "question_type             int64\n",
       "group_name                int64\n",
       "track_name               uint32\n",
       "subtrack_name             int64\n",
       "tag_string               object\n",
       "answer_id                uint16\n",
       "game_type                 int64\n",
       "num_players               int64\n",
       "question_set_id           int64\n",
       "round_started_at_date    object\n",
       "round_started_at_time    object\n",
       "answered_at_date         object\n",
       "answered_at_time         object\n",
       "deactivated_at_date      object\n",
       "deactivated_at_time      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check datatypes\n",
    "train_users.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we need the newly generated columns to be in a specific format.\n",
    "# the round_started_at_date , round_started_at_time , answered_at_time , answered_at_date , \n",
    "# deactivated_at_time , deactivated_at_date are in object format .\n",
    "# for our model we need them to be in timestamp format .\n",
    "# Hence the format conversion is done ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to datetime format\n",
    "train_users['round_started_at_date'] = pd.to_datetime(train_users['round_started_at_date'], format='%Y-%m-%d')\n",
    "\n",
    "train_users['round_started_at_time'] = pd.to_datetime(train_users['round_started_at_time'], format='%H:%M:%S')\n",
    "\n",
    "train_users['answered_at_date'] = pd.to_datetime(train_users['round_started_at_date'], format='%Y-%m-%d')\n",
    "\n",
    "train_users['answered_at_time'] = pd.to_datetime(train_users['answered_at_time'], format='%H:%M:%S')\n",
    "\n",
    "train_users['deactivated_at_date'] = pd.to_datetime(train_users['deactivated_at_date'], format='%Y-%m-%d')\n",
    "\n",
    "train_users['deactivated_at_time'] = pd.to_datetime(train_users['round_started_at_time'], format='%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sphoorti/anaconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py:279: FutureWarning: In the future, NAT != NAT will be True rather than False.\n",
      "  flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>outcome</th>\n",
       "      <th>user_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question_type</th>\n",
       "      <th>group_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>subtrack_name</th>\n",
       "      <th>tag_string</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>game_type</th>\n",
       "      <th>num_players</th>\n",
       "      <th>question_set_id</th>\n",
       "      <th>round_started_at_date</th>\n",
       "      <th>round_started_at_time</th>\n",
       "      <th>answered_at_date</th>\n",
       "      <th>answered_at_time</th>\n",
       "      <th>deactivated_at_date</th>\n",
       "      <th>deactivated_at_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20282</td>\n",
       "      <td>5560</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>1060</td>\n",
       "      <td>6540</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1567</td>\n",
       "      <td>688</td>\n",
       "      <td>73019</td>\n",
       "      <td>688</td>\n",
       "      <td>73065</td>\n",
       "      <td>688</td>\n",
       "      <td>73019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20282</td>\n",
       "      <td>4681</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1221</td>\n",
       "      <td>4742</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1227</td>\n",
       "      <td>688</td>\n",
       "      <td>73138</td>\n",
       "      <td>688</td>\n",
       "      <td>73201</td>\n",
       "      <td>688</td>\n",
       "      <td>73138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20282</td>\n",
       "      <td>1529</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1272</td>\n",
       "      <td>4309</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1148</td>\n",
       "      <td>688</td>\n",
       "      <td>73228</td>\n",
       "      <td>688</td>\n",
       "      <td>73283</td>\n",
       "      <td>688</td>\n",
       "      <td>73228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20282</td>\n",
       "      <td>2908</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1272</td>\n",
       "      <td>4408</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1168</td>\n",
       "      <td>688</td>\n",
       "      <td>73309</td>\n",
       "      <td>688</td>\n",
       "      <td>73352</td>\n",
       "      <td>688</td>\n",
       "      <td>73309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20282</td>\n",
       "      <td>1773</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>801</td>\n",
       "      <td>10822</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2318</td>\n",
       "      <td>688</td>\n",
       "      <td>73377</td>\n",
       "      <td>688</td>\n",
       "      <td>73535</td>\n",
       "      <td>688</td>\n",
       "      <td>73377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   correct  outcome  user_id  question_id  question_type  group_name  \\\n",
       "0        0        2    20282         5560              0           1   \n",
       "1        1        1    20282         4681              0           1   \n",
       "2        1        1    20282         1529              0           1   \n",
       "3        1        1    20282         2908              0           1   \n",
       "4        1        1    20282         1773              0           1   \n",
       "\n",
       "   track_name  subtrack_name  tag_string  answer_id  game_type  num_players  \\\n",
       "0           5             14        1060       6540          7            1   \n",
       "1           5              0        1221       4742          7            1   \n",
       "2           5              0        1272       4309          7            1   \n",
       "3           5              0        1272       4408          7            1   \n",
       "4           5             11         801      10822          7            1   \n",
       "\n",
       "   question_set_id  round_started_at_date  round_started_at_time  \\\n",
       "0             1567                    688                  73019   \n",
       "1             1227                    688                  73138   \n",
       "2             1148                    688                  73228   \n",
       "3             1168                    688                  73309   \n",
       "4             2318                    688                  73377   \n",
       "\n",
       "   answered_at_date  answered_at_time  deactivated_at_date  \\\n",
       "0               688             73065                  688   \n",
       "1               688             73201                  688   \n",
       "2               688             73283                  688   \n",
       "3               688             73352                  688   \n",
       "4               688             73535                  688   \n",
       "\n",
       "   deactivated_at_time  \n",
       "0                73019  \n",
       "1                73138  \n",
       "2                73228  \n",
       "3                73309  \n",
       "4                73377  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label encoding of date, time and tag_string attributes\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train_users['round_started_at_date'] = le.fit_transform(train_users['round_started_at_date'])\n",
    "train_users['answered_at_date'] = le.fit_transform(train_users['answered_at_date'])\n",
    "train_users['deactivated_at_date'] = le.fit_transform(train_users['deactivated_at_date'])\n",
    "train_users['round_started_at_time'] = le.fit_transform(train_users['round_started_at_time'])\n",
    "train_users['answered_at_time'] = le.fit_transform(train_users['answered_at_time'])\n",
    "train_users['deactivated_at_time'] = le.fit_transform(train_users['deactivated_at_time'])\n",
    "#train_users['date_of_test'] = le.fit_transform(train_users['date_of_test'])\n",
    "train_users['tag_string'] = le.fit_transform(train_users['tag_string'])\n",
    "#train_users['time_taken'] = le.fit_transform(train_users['time_taken'])\n",
    "train_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for selecting attributes\n",
    "y = train_users['outcome']\n",
    "#x = train_users[['correct','tag_string','subtrack_name','user_id']]\n",
    "x = train_users.drop('outcome',axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sphoorti/.local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import cross_validation\n",
    "## Spliting of training dataset into 80% training data and 20% testing data randomly\n",
    "X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(x, y , test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Now that we have our data clean and transformed to our suitable form, we now predict the necessary features \n",
    "# required for predicting the desired attribute's value (atribute : outcome)\n",
    "# We have used ensembles to find the important attributes . \n",
    "# ensembles can be shown to have more flexibility in the functions they can represent . \n",
    "# this feature of ensemble allowed us to use ensemble as a feature selector .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.70656498  0.00338748  0.00227329  0.00232035  0.0027363   0.00847598\n",
      "  0.0029619   0.00412972  0.0848564   0.0025671   0.00232093  0.00660038\n",
      "  0.00362583  0.01206047  0.00389289  0.12259883  0.00359215  0.02503503]\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance with Extra Trees Classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# load data\n",
    "# feature extraction\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(x, y)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.055555555555555552"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=model.feature_importances_\n",
    "\n",
    "m.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 0 (0.706565)\n",
      "2. feature 15 (0.122599)\n",
      "3. feature 8 (0.084856)\n",
      "4. feature 17 (0.025035)\n",
      "5. feature 13 (0.012060)\n",
      "6. feature 5 (0.008476)\n",
      "7. feature 11 (0.006600)\n",
      "8. feature 7 (0.004130)\n",
      "9. feature 14 (0.003893)\n",
      "10. feature 12 (0.003626)\n",
      "11. feature 16 (0.003592)\n",
      "12. feature 1 (0.003387)\n",
      "13. feature 6 (0.002962)\n",
      "14. feature 4 (0.002736)\n",
      "15. feature 9 (0.002567)\n",
      "16. feature 10 (0.002321)\n",
      "17. feature 3 (0.002320)\n",
      "18. feature 2 (0.002273)\n"
     ]
    }
   ],
   "source": [
    "indices = np.argsort(m)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(x.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], m[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f059a04b4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(x.shape[1]), m[indices],\n",
    "       color=\"r\", align=\"center\")\n",
    "plt.xticks(range(x.shape[1]), indices)\n",
    "plt.xlim([-1, x.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. GNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "# Different classification techniques\n",
    "## Decision Tree \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for selecting attributes\n",
    "y_new = train_users['outcome']\n",
    "#x = train_users[['correct','tag_string','subtrack_name','user_id']]\n",
    "x_new = train_users[['correct','tag_string','answered_at_date']]\n",
    "\n",
    "\n",
    "from sklearn import cross_validation\n",
    "## Spliting of training dataset into 80% training data and 20% testing data randomly\n",
    "X_train1, X_test1, Y_train1, Y_test1 = cross_validation.train_test_split(x_new, y_new , test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Spliting of training dataset into 80% training data and 20% testing data randomly\n",
    "X_trainVal, X_testVal, Y_trainVal, Y_testVal = cross_validation.train_test_split(X_train1, Y_train1 , test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=1, n_neighbors=2, p=2, radius=1.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbrs = NearestNeighbors(n_neighbors=2, algorithm='auto').fit(X_train1)\n",
    "distances, indices = nbrs.kneighbors(X_train1)\n",
    "nbrs.fit(X_train1, Y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  72.151 % for K-Value: 1\n",
      "Accuracy is  72.2405 % for K-Value: 2\n",
      "Accuracy is  70.0145 % for K-Value: 3\n",
      "Accuracy is  69.9415 % for K-Value: 4\n",
      "Accuracy is  68.9065 % for K-Value: 5\n",
      "Accuracy is  68.3215 % for K-Value: 6\n",
      "Accuracy is  67.8055 % for K-Value: 7\n",
      "Accuracy is  67.4565 % for K-Value: 8\n",
      "Accuracy is  66.8625 % for K-Value: 9\n",
      "Accuracy is  66.5825 % for K-Value: 10\n",
      "Accuracy is  66.145 % for K-Value: 11\n",
      "Accuracy is  65.7475 % for K-Value: 12\n",
      "Accuracy is  65.5015 % for K-Value: 13\n",
      "Accuracy is  65.285 % for K-Value: 14\n",
      "Accuracy is  64.929 % for K-Value: 15\n",
      "Accuracy is  64.7615 % for K-Value: 16\n",
      "Accuracy is  64.4735 % for K-Value: 17\n",
      "Accuracy is  64.257 % for K-Value: 18\n",
      "Accuracy is  63.953 % for K-Value: 19\n",
      "Accuracy is  63.7575 % for K-Value: 20\n"
     ]
    }
   ],
   "source": [
    "#accuracy for train split\n",
    "for K in range(20):\n",
    " K_value =K+1\n",
    " neigh = KNeighborsClassifier(n_neighbors = K_value, weights='uniform', algorithm='auto')\n",
    " neigh.fit(X_train1, Y_train1) \n",
    " y_pred = neigh.predict(X_test1)\n",
    " print( \"Accuracy is \", accuracy_score(Y_test1,y_pred)*100,\"% for K-Value:\",K_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  69.8155 % for K-Value: 1\n",
      "Accuracy is  70.063 % for K-Value: 2\n",
      "Accuracy is  67.819 % for K-Value: 3\n",
      "Accuracy is  67.8175 % for K-Value: 4\n",
      "Accuracy is  66.9075 % for K-Value: 5\n",
      "Accuracy is  66.4915 % for K-Value: 6\n",
      "Accuracy is  65.871 % for K-Value: 7\n",
      "Accuracy is  65.5935 % for K-Value: 8\n",
      "Accuracy is  65.003 % for K-Value: 9\n",
      "Accuracy is  64.7645 % for K-Value: 10\n",
      "Accuracy is  64.39 % for K-Value: 11\n",
      "Accuracy is  64.102 % for K-Value: 12\n",
      "Accuracy is  63.7885 % for K-Value: 13\n",
      "Accuracy is  63.5705 % for K-Value: 14\n",
      "Accuracy is  63.3205 % for K-Value: 15\n",
      "Accuracy is  63.0905 % for K-Value: 16\n",
      "Accuracy is  62.8375 % for K-Value: 17\n",
      "Accuracy is  62.66 % for K-Value: 18\n",
      "Accuracy is  62.4335 % for K-Value: 19\n",
      "Accuracy is  62.2275 % for K-Value: 20\n"
     ]
    }
   ],
   "source": [
    "#accuracy for valid data\n",
    "for K in range(20):\n",
    " K_value =K+1\n",
    " neigh = KNeighborsClassifier(n_neighbors = K_value, weights='uniform', algorithm='auto')\n",
    " neigh.fit(X_trainVal, Y_trainVal) \n",
    " y_pred = neigh.predict(X_testVal)\n",
    " print( \"Accuracy is \", accuracy_score(Y_testVal,y_pred)*100,\"% for K-Value:\",K_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sphoorti/.local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 50,  80, 110])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sizes, train_scores, valid_scores = learning_curve(neigh, X_train1, Y_train1, train_sizes=[50, 80, 110], cv=5)\n",
    "train_sizes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X_train1, Y_train1, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X_train1, Y_train1, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from '/home/sphoorti/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxhhjPJYUjDHGeP4/t38UAIbc6n4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0599c0cb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.4, random_state=0)\n",
    "\n",
    "estimator = KNeighborsClassifier()\n",
    "plot_learning_curve(estimator, title, X_trainVal, Y_trainVal, ylim=(0.1, 1.00), cv=cv, n_jobs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f0599d379e8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0599d78710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# plot the relationship between K and testing accuracy\n",
    "# plt.plot(x_axis, y_axis)\n",
    "plt.plot(k_range, scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the knn classifier for k = 3 is 70%\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3,algorithm='auto')\n",
    "\n",
    "# fitting the model\n",
    "knn.fit(X_train1, Y_train1)\n",
    "\n",
    "# predict the response\n",
    "pred = knn.predict(X_test1)\n",
    "\n",
    "# evaluate accuracy\n",
    "acc = accuracy_score(Y_test1, pred) * 100\n",
    "print('\\nThe accuracy of the knn classifier for k = 3 is %d%%' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 ..., 4 1 4]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating odd list of K for KNN\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "myList = list(range(0,20))\n",
    "neighbors = list(filter(lambda x: x % 3 != 0, myList))\n",
    "\n",
    "\n",
    "# empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "\n",
    "# perform 10-fold cross validation\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train1, Y_train1, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "# changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "# determining best k\n",
    "optimal_k = neighbors[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal number of neighbors is %d.' % optimal_k)\n",
    "\n",
    "# plot misclassification error vs k \n",
    "plt.plot(neighbors, MSE)\n",
    "plt.xlabel('Number of Neighbors K')\n",
    "plt.ylabel('Misclassification Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of GaussianNB with different parameters\n",
      "[0]     [0.8825925]\n",
      "Validation accuracy of GaussianNB with different parameters\n",
      "[0]     [0.88258000000000003]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models= []\n",
    "score_training= []\n",
    "score_validation= []\n",
    "\n",
    "\n",
    "d={'param1': { \"priors\": [0.2, 0.8] }}\n",
    "\n",
    "\n",
    "print(\"Training accuracy of GaussianNB with different parameters\")\n",
    "for i in range(0,1,1):\n",
    "    a = list(d.values())[i]\n",
    "   \n",
    "    clf = GaussianNB()\n",
    "     \n",
    "    clf.fit(X_train1, Y_train1)\n",
    "    prediction = clf.predict(X_train1)\n",
    "    ## Computing accuracy\n",
    "    from sklearn.metrics import accuracy_score\n",
    "        \n",
    "    models.append(i)\n",
    "    score_training.append(accuracy_score(prediction, Y_train1))\n",
    "    \n",
    "    \n",
    "print(models, \"   \", score_training)\n",
    "\n",
    "\n",
    "print(\"Validation accuracy of GaussianNB with different parameters\")\n",
    "for i in range(0,1,1):\n",
    "    a = list(d.values())[i]\n",
    "\n",
    "    clf = GaussianNB()\n",
    "     \n",
    "    clf.fit(X_trainVal, Y_trainVal)\n",
    "    prediction = clf.predict(X_testVal)\n",
    "    ## Computing accuracy\n",
    "    from sklearn.metrics import accuracy_score\n",
    "        \n",
    "    score_validation.append(accuracy_score(prediction, Y_testVal))\n",
    "    \n",
    "    \n",
    "print(models, \"   \", score_validation)\n",
    "\n",
    "\n",
    "#measure_performance(features_train, labels_train, clf)\n",
    "\n",
    "#matrix = confusion_matrix(labels_test, prediction)\n",
    "#print(matrix)\n",
    "\n",
    "#report = classification_report(labels_test, prediction)\n",
    "#print(report)\n",
    "\n",
    "#rms = mean_squared_error(labels_test, prediction)\n",
    "#print(\"Root mean square error: \",rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of GaussianNB with different parameters\n",
      "[0]     [0.8825925]\n",
      "Validation accuracy of GaussianNB with different parameters\n",
      "[0]     [0.88258000000000003]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models= []\n",
    "score_training= []\n",
    "score_validation= []\n",
    "\n",
    "\n",
    "d={'param2': { \"priors\": [0.4, 0.6] }}\n",
    "\n",
    "\n",
    "print(\"Training accuracy of GaussianNB with different parameters\")\n",
    "for i in range(0,1,1):\n",
    "    a = list(d.values())[i]\n",
    "   \n",
    "    clf = GaussianNB()\n",
    "     \n",
    "    clf.fit(X_train1, Y_train1)\n",
    "    prediction = clf.predict(X_train1)\n",
    "    ## Computing accuracy\n",
    "    from sklearn.metrics import accuracy_score\n",
    "        \n",
    "    models.append(i)\n",
    "    score_training.append(accuracy_score(prediction, Y_train1))\n",
    "    \n",
    "    \n",
    "print(models, \"   \", score_training)\n",
    "\n",
    "\n",
    "print(\"Validation accuracy of GaussianNB with different parameters\")\n",
    "for i in range(0,1,1):\n",
    "    a = list(d.values())[i]\n",
    "\n",
    "    clf = GaussianNB()\n",
    "     \n",
    "    clf.fit(X_trainVal, Y_trainVal)\n",
    "    prediction = clf.predict(X_testVal)\n",
    "    ## Computing accuracy\n",
    "    from sklearn.metrics import accuracy_score\n",
    "        \n",
    "    score_validation.append(accuracy_score(prediction, Y_testVal))\n",
    "    \n",
    "    \n",
    "print(models, \"   \", score_validation)\n",
    "\n",
    "\n",
    "#measure_performance(features_train, labels_train, clf)\n",
    "\n",
    "#matrix = confusion_matrix(labels_test, prediction)\n",
    "#print(matrix)\n",
    "\n",
    "#report = classification_report(labels_test, prediction)\n",
    "#print(report)\n",
    "\n",
    "#rms = mean_squared_error(labels_test, prediction)\n",
    "#print(\"Root mean square error: \",rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of GaussianNB with different parameters\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-6e97b758c920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training accuracy of GaussianNB with different parameters\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "models= []\n",
    "score_training= []\n",
    "score_validation= []\n",
    "\n",
    "\n",
    "d={'param2': { \"priors\": [0.4, 0.6] },\n",
    "   'param3': { \"priors\": [0.5, 0.5] },\n",
    "   'param4': { \"priors\": [0.6, 0.4] }, \n",
    "   'param5': { \"priors\": [0.8, 0.2] }}\n",
    "\n",
    "\n",
    "print(\"Training accuracy of GaussianNB with different parameters\")\n",
    "for i in range(0,5,1):\n",
    "    a = list(d.values())[i]\n",
    "   \n",
    "    clf = GaussianNB()\n",
    "     \n",
    "    clf.fit(X_train1, Y_train1)\n",
    "    prediction = clf.predict(X_train1)\n",
    "    ## Computing accuracy\n",
    "    from sklearn.metrics import accuracy_score\n",
    "        \n",
    "    models.append(i)\n",
    "    score_training.append(accuracy_score(prediction, Y_train1))\n",
    "    \n",
    "    \n",
    "print(models, \"   \", score_training)\n",
    "\n",
    "\n",
    "print(\"Validation accuracy of GaussianNB with different parameters\")\n",
    "for i in range(0,5,1):\n",
    "    a = list(d.values())[i]\n",
    "\n",
    "    clf = GaussianNB()\n",
    "     \n",
    "    clf.fit(X_trainVal, Y_trainVal)\n",
    "    prediction = clf.predict(X_testVal)\n",
    "    ## Computing accuracy\n",
    "    from sklearn.metrics import accuracy_score\n",
    "        \n",
    "    score_validation.append(accuracy_score(prediction, Y_testVal))\n",
    "    \n",
    "    \n",
    "print(models, \"   \", score_validation)\n",
    "\n",
    "\n",
    "#measure_performance(features_train, labels_train, clf)\n",
    "\n",
    "#matrix = confusion_matrix(labels_test, prediction)\n",
    "#print(matrix)\n",
    "\n",
    "#report = classification_report(labels_test, prediction)\n",
    "#print(report)\n",
    "\n",
    "#rms = mean_squared_error(labels_test, prediction)\n",
    "#print(\"Root mean square error: \",rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_train = []\n",
    "error_validation = []\n",
    "\n",
    "for i in range(0,5,1):\n",
    "    temp = 1 - score_training[i]\n",
    "    error_train.append(temp)\n",
    "\n",
    "\n",
    "for i in range(0,5,1):\n",
    "    temp = 1 - score_validation[i]\n",
    "    error_validation.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(index=[1,2,3,4,5])\n",
    "\n",
    "dat['training error'] = error_train \n",
    "dat['validation error'] = error_validation\n",
    "\n",
    "dat.plot(title=\"Models Pereformance Graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There was no variation in GuassianNB method when tuned with different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "# Different classification techniques\n",
    "## Decision Tree \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models= []\n",
    "score_training= []\n",
    "score_validation= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d={'param1': {\"splitter\": \"random\", \"criterion\":\"entropy\", \"max_depth\": 20, \"max_leaf_nodes\": 2},\n",
    "   'param2': {\"splitter\": \"random\", \"criterion\":\"entropy\", \"max_depth\": 20, \"max_leaf_nodes\": 200},\n",
    "   'param3': {\"splitter\": \"random\", \"criterion\":\"entropy\", \"max_depth\": 200, \"max_leaf_nodes\": 2},\n",
    "   'param4': {\"splitter\": \"random\", \"criterion\":\"entropy\", \"max_depth\": 200, \"max_leaf_nodes\": 200},\n",
    "   'param5': {\"splitter\": \"best\", \"criterion\":\"entropy\", \"max_depth\": 20, \"max_leaf_nodes\": 2},\n",
    "   'param6': {\"splitter\": \"best\", \"criterion\":\"entropy\", \"max_depth\": 20, \"max_leaf_nodes\": 200},\n",
    "   'param7': {\"splitter\": \"best\", \"criterion\":\"entropy\", \"max_depth\": 200, \"max_leaf_nodes\": 2},\n",
    "   'param8': {\"splitter\": \"best\", \"criterion\":\"entropy\", \"max_depth\": 200, \"max_leaf_nodes\": 200},\n",
    "   'param9':  {\"splitter\": \"random\", \"criterion\":\"gini\", \"max_depth\": 20, \"max_leaf_nodes\": 2},\n",
    "   'param10': {\"splitter\": \"random\", \"criterion\":\"gini\", \"max_depth\": 20, \"max_leaf_nodes\": 200},\n",
    "   'param11': {\"splitter\": \"random\", \"criterion\":\"gini\", \"max_depth\": 200, \"max_leaf_nodes\": 2},\n",
    "   'param12': {\"splitter\": \"random\", \"criterion\":\"gini\", \"max_depth\": 200, \"max_leaf_nodes\": 200},\n",
    "   'param13': {\"splitter\": \"best\", \"criterion\":\"gini\", \"max_depth\": 20, \"max_leaf_nodes\": 2},\n",
    "   'param14': {\"splitter\": \"best\", \"criterion\":\"gini\", \"max_depth\": 20, \"max_leaf_nodes\": 200},\n",
    "   'param15': {\"splitter\": \"best\", \"criterion\":\"gini\", \"max_depth\": 200, \"max_leaf_nodes\": 2},\n",
    "   'param16': {\"splitter\": \"best\", \"criterion\":\"gini\", \"max_depth\": 200, \"max_leaf_nodes\": 200},\n",
    "   'param17':  {\"splitter\": \"best\", \"criterion\":\"entropy\", \"max_depth\": 20},\n",
    "   'param18':  {\"splitter\": \"best\", \"criterion\":\"gini\", \"max_depth\": 20},\n",
    "   'param19':  {\"splitter\": \"random\", \"criterion\":\"entropy\", \"max_depth\": 200},\n",
    "   'param20':  {\"splitter\": \"random\", \"criterion\":\"gini\", \"max_depth\": 200}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training accuracy of Decision Tree with different parameters\")\n",
    "v = list(d.values())\n",
    "\n",
    "for i in range(0,20,1):\n",
    "    a = v[i]\n",
    "\n",
    "    clf = tree.DecisionTreeClassifier(**a)\n",
    "     \n",
    "    clf.fit(X_train, Y_train)\n",
    "    prediction = clf.predict(X_train)\n",
    "    ## Computing accuracy\n",
    "    from sklearn.metrics import accuracy_score\n",
    "        \n",
    "    models.append(i)\n",
    "    score_training.append(accuracy_score(prediction, Y_train))\n",
    "    \n",
    "    \n",
    "print(models, \"   \", score_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Validation accuracy of Decision Tree with different parameters\")\n",
    "v = list(d.values())\n",
    "for i in range(0,20,1):\n",
    "    a = v[i]\n",
    "\n",
    "    clf = tree.DecisionTreeClassifier(**a)\n",
    "     \n",
    "    clf.fit(X_train, Y_train)\n",
    "    prediction = clf.predict(X_test)\n",
    "    ## Computing accuracy\n",
    "    from sklearn.metrics import accuracy_score\n",
    "        \n",
    "    score_validation.append(accuracy_score(prediction, Y_test))\n",
    "    \n",
    "    \n",
    "print(models, \"   \", score_validation)\n",
    "\n",
    "\n",
    "#measure_performance(features_train, labels_train, clf)\n",
    "\n",
    "#matrix = confusion_matrix(labels_test, prediction)\n",
    "#print(matrix)\n",
    "\n",
    "#report = classification_report(labels_test, prediction)\n",
    "#print(report)\n",
    "\n",
    "#rms = mean_squared_error(labels_test, prediction)\n",
    "#print(\"Root mean square error: \",rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_train = []\n",
    "error_validation = []\n",
    "\n",
    "\n",
    "for i in range(0,20,1):\n",
    "    temp = 1 - score_training[i]\n",
    "    error_train.append(temp)\n",
    "    \n",
    "print(error_train)\n",
    "    \n",
    "for i in range(0,20,1):\n",
    "    temp = 1 - score_validation[i]\n",
    "    error_validation.append(temp)\n",
    "    \n",
    "print(error_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [a - b for a, b in zip(error_validation, error_train)]\n",
    "print(C)\n",
    "\n",
    "\n",
    "m = min(i for i in C if i > 0)\n",
    "\n",
    "print(\"Position:\", C.index(m))\n",
    "print(\"Value:\", m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelno = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(index=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\n",
    "dat['model'] = modelno\n",
    "dat['training error'] = error_train \n",
    "dat['validation error'] = error_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.set_index(\"model\",inplace=True)\n",
    "dat.plot(title=\"Models Pereformance Graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The best model which has least difference between training and validation error is model 12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models= []\n",
    "score_training= []\n",
    "score_validation= []\n",
    "\n",
    "\n",
    "d={'param1': {\"n_estimators\": 20, \"criterion\":\"entropy\", \"max_depth\": 20, \"max_leaf_nodes\": 2},\n",
    "   'param2': {\"n_estimators\": 20, \"criterion\":\"entropy\", \"max_depth\": 20, \"max_leaf_nodes\": 200},\n",
    "   'param3': {\"n_estimators\": 20, \"criterion\":\"entropy\", \"max_depth\": 200, \"max_leaf_nodes\": 2},\n",
    "   'param4': {\"n_estimators\": 20, \"criterion\":\"entropy\", \"max_depth\": 200, \"max_leaf_nodes\": 200},\n",
    "   'param5': {\"n_estimators\": 200, \"criterion\":\"entropy\", \"max_depth\": 20, \"max_leaf_nodes\": 2},\n",
    "   'param6': {\"n_estimators\": 200, \"criterion\":\"entropy\", \"max_depth\": 20, \"max_leaf_nodes\": 200},\n",
    "   'param7': {\"n_estimators\": 200, \"criterion\":\"entropy\", \"max_depth\": 200, \"max_leaf_nodes\": 2},\n",
    "   'param8': {\"n_estimators\": 200, \"criterion\":\"entropy\", \"max_depth\": 200, \"max_leaf_nodes\": 200},\n",
    "   'param9':  {\"n_estimators\": 20, \"criterion\":\"gini\", \"max_depth\": 20, \"max_leaf_nodes\": 2},\n",
    "   'param10': {\"n_estimators\": 20, \"criterion\":\"gini\", \"max_depth\": 20, \"max_leaf_nodes\": 200},\n",
    "   'param11': {\"n_estimators\": 20, \"criterion\":\"gini\", \"max_depth\": 200, \"max_leaf_nodes\": 2},\n",
    "   'param12': {\"n_estimators\": 20, \"criterion\":\"gini\", \"max_depth\": 200, \"max_leaf_nodes\": 200},\n",
    "   'param13': {\"n_estimators\": 200, \"criterion\":\"gini\", \"max_depth\": 20, \"max_leaf_nodes\": 2},\n",
    "   'param14': {\"n_estimators\": 200, \"criterion\":\"gini\", \"max_depth\": 20, \"max_leaf_nodes\": 200},\n",
    "   'param15': {\"n_estimators\": 200, \"criterion\":\"gini\", \"max_depth\": 200, \"max_leaf_nodes\": 2},\n",
    "   'param16': {\"n_estimators\": 200, \"criterion\":\"gini\", \"max_depth\": 200, \"max_leaf_nodes\": 200}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training accuracy of Random Forest Classifier with different parameters\")\n",
    "v = list(d.values())\n",
    "for i in range(0,16,1):\n",
    "    a = v[i]\n",
    "\n",
    "    clf = RandomForestClassifier(**a)\n",
    "     \n",
    "    clf.fit(X_train, Y_train)\n",
    "    prediction = clf.predict(X_train)\n",
    "    ## Computing accuracy\n",
    "    from sklearn.metrics import accuracy_score\n",
    "        \n",
    "    models.append(i)\n",
    "    score_training.append(accuracy_score(prediction, Y_train))\n",
    "    \n",
    "    \n",
    "print(models, \"   \", score_training)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Validation accuracy of Random Forest Classifier with different parameters\")\n",
    "v = list(d.values())\n",
    "for i in range(0,16,1):\n",
    "    a = v[i]\n",
    "\n",
    "    clf = RandomForestClassifier(**a)\n",
    "     \n",
    "    clf.fit(X_train, Y_train)\n",
    "    prediction = clf.predict(X_test)\n",
    "    ## Computing accuracy\n",
    "    from sklearn.metrics import accuracy_score\n",
    "        \n",
    "    score_validation.append(accuracy_score(prediction, Y_test))\n",
    "    \n",
    "    \n",
    "print(models, \"   \", score_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "## Spliting of training dataset into 80% training data and 20% testing data randomly\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(x_new, y_new, test_size=0.2, random_state=42)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = linear_model.LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "\n",
    "clf.fit(features_train, labels_train)\n",
    "prediction = clf.predict(features_test)\n",
    "## Computing accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(prediction, labels_test))\n",
    "\n",
    "matrix = confusion_matrix(labels_test, prediction)\n",
    "print(matrix)\n",
    "\n",
    "rms = mean_squared_error(labels_test, prediction)\n",
    "print(\"Root mean square error: \",rms)\n",
    "\n",
    "report = classification_report(labels_test, prediction)\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_users.query('outcome != 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_post=train_users[['correct','tag_string','answered_at_date']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# models after post processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "## Spliting of training dataset into 80% training data and 20% testing data randomly\n",
    "#features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train2, X_test2, Y_train2, Y_test2 = cross_validation.train_test_split(x_post, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "# Different classification techniques\n",
    "## Decision Tree \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "\n",
    "models= []\n",
    "score_training= []\n",
    "score_validation= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d={'param1': {\"splitter\": \"random\", \"criterion\":\"entropy\", \"max_depth\": 20, \"max_leaf_nodes\": 2},\n",
    "   'param2': {\"splitter\": \"random\", \"criterion\":\"entropy\", \"max_depth\": 20, \"max_leaf_nodes\": 200},\n",
    "   'param3': {\"splitter\": \"random\", \"criterion\":\"entropy\", \"max_depth\": 200, \"max_leaf_nodes\": 2},\n",
    "   'param4': {\"splitter\": \"random\", \"criterion\":\"entropy\", \"max_depth\": 200, \"max_leaf_nodes\": 200},\n",
    "   'param5': {\"splitter\": \"best\", \"criterion\":\"entropy\", \"max_depth\": 20, \"max_leaf_nodes\": 2},\n",
    "   'param6': {\"splitter\": \"best\", \"criterion\":\"entropy\", \"max_depth\": 20, \"max_leaf_nodes\": 200},\n",
    "   'param7': {\"splitter\": \"best\", \"criterion\":\"entropy\", \"max_depth\": 200, \"max_leaf_nodes\": 2},\n",
    "   'param8': {\"splitter\": \"best\", \"criterion\":\"entropy\", \"max_depth\": 200, \"max_leaf_nodes\": 200},\n",
    "   'param9':  {\"splitter\": \"random\", \"criterion\":\"gini\", \"max_depth\": 20, \"max_leaf_nodes\": 2},\n",
    "   'param10': {\"splitter\": \"random\", \"criterion\":\"gini\", \"max_depth\": 20, \"max_leaf_nodes\": 200},\n",
    "   'param11': {\"splitter\": \"random\", \"criterion\":\"gini\", \"max_depth\": 200, \"max_leaf_nodes\": 2},\n",
    "   'param12': {\"splitter\": \"random\", \"criterion\":\"gini\", \"max_depth\": 200, \"max_leaf_nodes\": 200},\n",
    "   'param13': {\"splitter\": \"best\", \"criterion\":\"gini\", \"max_depth\": 20, \"max_leaf_nodes\": 2},\n",
    "   'param14': {\"splitter\": \"best\", \"criterion\":\"gini\", \"max_depth\": 20, \"max_leaf_nodes\": 200},\n",
    "   'param15': {\"splitter\": \"best\", \"criterion\":\"gini\", \"max_depth\": 200, \"max_leaf_nodes\": 2},\n",
    "   'param16': {\"splitter\": \"best\", \"criterion\":\"gini\", \"max_depth\": 200, \"max_leaf_nodes\": 200},\n",
    "   'param17':  {\"splitter\": \"best\", \"criterion\":\"entropy\", \"max_depth\": 20},\n",
    "   'param18':  {\"splitter\": \"best\", \"criterion\":\"gini\", \"max_depth\": 20},\n",
    "   'param19':  {\"splitter\": \"random\", \"criterion\":\"entropy\", \"max_depth\": 200},\n",
    "   'param20':  {\"splitter\": \"random\", \"criterion\":\"gini\", \"max_depth\": 200}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training accuracy of Decision Tree with different parameters\")\n",
    "v = list(d.values())\n",
    "\n",
    "for i in range(0,20,1):\n",
    "    a = v[i]\n",
    "\n",
    "    clf = tree.DecisionTreeClassifier(**a)\n",
    "     \n",
    "    clf.fit(X_train2, Y_train2)\n",
    "    prediction = clf.predict(X_train2)\n",
    "    ## Computing accuracy\n",
    "    from sklearn.metrics import accuracy_score\n",
    "        \n",
    "    models.append(i)\n",
    "    score_training.append(accuracy_score(prediction, Y_train2))\n",
    "    \n",
    "    \n",
    "print(models, \"   \", score_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Validation accuracy of Decision Tree with different parameters\")\n",
    "v = list(d.values())\n",
    "for i in range(0,20,1):\n",
    "    a = v[i]\n",
    "\n",
    "    clf = tree.DecisionTreeClassifier(**a)\n",
    "     \n",
    "    clf.fit(X_train, Y_train)\n",
    "    prediction = clf.predict(X_test)\n",
    "    ## Computing accuracy\n",
    "    from sklearn.metrics import accuracy_score\n",
    "        \n",
    "    score_validation.append(accuracy_score(prediction, Y_test))\n",
    "    \n",
    "    \n",
    "print(models, \"   \", score_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_train = []\n",
    "error_validation = []\n",
    "\n",
    "\n",
    "for i in range(0,20,1):\n",
    "    temp = 1 - score_training[i]\n",
    "    error_train.append(temp)\n",
    "    \n",
    "print(error_train)\n",
    "    \n",
    "for i in range(0,20,1):\n",
    "    temp = 1 - score_validation[i]\n",
    "    error_validation.append(temp)\n",
    "    \n",
    "print(error_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [a - b for a, b in zip(error_validation, error_train)]\n",
    "print(C)\n",
    "\n",
    "\n",
    "m = min(i for i in C if i > 0)\n",
    "\n",
    "print(\"Position:\", C.index(m))\n",
    "print(\"Value:\", m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelno = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "dat = pd.DataFrame(index=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\n",
    "dat['model'] = modelno\n",
    "dat['training error'] = error_train \n",
    "dat['validation error'] = error_validation\n",
    "\n",
    "dat.set_index(\"model\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.plot(title=\"Models Pereformance Graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  The best model which has least difference between training and validation error is model 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. GNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models= []\n",
    "score_training= []\n",
    "score_validation= []\n",
    "\n",
    "\n",
    "d={'param1': { \"priors\": [0.2, 0.8] },\n",
    "   'param2': { \"priors\": [0.4, 0.6] },\n",
    "   'param3': { \"priors\": [0.5, 0.5] },\n",
    "   'param4': { \"priors\": [0.6, 0.4] }, \n",
    "   'param5': { \"priors\": [0.8, 0.2] }}\n",
    "\n",
    "\n",
    "print(\"Training accuracy of GaussianNB with different parameters\")\n",
    "for i in range(0,5,1):\n",
    "    a = list(d.values())[i]\n",
    "   \n",
    "    clf = GaussianNB()\n",
    "     \n",
    "    clf.fit(X_train2, Y_train2)\n",
    "    prediction = clf.predict(X_train2)\n",
    "    ## Computing accuracy\n",
    "    from sklearn.metrics import accuracy_score\n",
    "        \n",
    "    models.append(i)\n",
    "    score_training.append(accuracy_score(prediction, Y_train2))\n",
    "    \n",
    "    \n",
    "print(models, \"   \", score_training)\n",
    "\n",
    "\n",
    "print(\"Validation accuracy of GaussianNB with different parameters\")\n",
    "for i in range(0,5,1):\n",
    "    a = list(d.values())[i]\n",
    "\n",
    "    clf = GaussianNB()\n",
    "     \n",
    "    clf.fit(X_train2, Y_train2)\n",
    "    prediction = clf.predict(X_test2)\n",
    "    ## Computing accuracy\n",
    "    from sklearn.metrics import accuracy_score\n",
    "        \n",
    "    score_validation.append(accuracy_score(prediction, Y_test2))\n",
    "    \n",
    "    \n",
    "print(models, \"   \", score_validation)\n",
    "\n",
    "\n",
    "#measure_performance(features_train, labels_train, clf)\n",
    "\n",
    "#matrix = confusion_matrix(labels_test, prediction)\n",
    "#print(matrix)\n",
    "\n",
    "#report = classification_report(labels_test, prediction)\n",
    "#print(report)\n",
    "\n",
    "#rms = mean_squared_error(labels_test, prediction)\n",
    "#print(\"Root mean square error: \",rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_train = []\n",
    "error_validation = []\n",
    "\n",
    "for i in range(0,5,1):\n",
    "    temp = 1 - score_training[i]\n",
    "    error_train.append(temp)\n",
    "\n",
    "\n",
    "for i in range(0,5,1):\n",
    "    temp = 1 - score_validation[i]\n",
    "    error_validation.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(index=[1,2,3,4,5])\n",
    "\n",
    "dat['training error'] = error_train \n",
    "dat['validation error'] = error_validation\n",
    "\n",
    "dat.plot(title=\"Models Pereformance Graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = linear_model.LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "\n",
    "clf.fit(X_train2, Y_train2)\n",
    "prediction = clf.predict(X_test2)\n",
    "## Computing accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(prediction, Y_test2))\n",
    "\n",
    "matrix = confusion_matrix(Y_test2, prediction)\n",
    "print(matrix)\n",
    "\n",
    "rms = mean_squared_error(labels_test, prediction)\n",
    "print(\"Root mean square error: \",rms)\n",
    "\n",
    "report = classification_report(Y_test2, prediction)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technique    Preprocessing------------------Post Preprocessing\n",
    "# DTC               12:- 0.878873085680831------ 4:- 0.87927511271583692\n",
    "# GNB               0.878873085680831------------0.878873085680831"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
